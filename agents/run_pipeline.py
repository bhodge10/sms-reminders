#!/usr/bin/env python
"""
Multi-Agent Monitoring Pipeline Runner
Runs all three agents in sequence:
  Agent 1: Interaction Monitor - Detect anomalies
  Agent 2: Issue Validator - Validate and categorize
  Agent 3: Resolution Tracker - Track health and report

Usage:
    python agents/run_pipeline.py              # Full pipeline
    python agents/run_pipeline.py --hours 48   # Custom time range
    python agents/run_pipeline.py --no-ai      # Skip AI validation
    python agents/run_pipeline.py --report     # Dry run (no DB writes)
    python agents/run_pipeline.py --snapshot   # Save daily health snapshot
"""

import sys
import os
import argparse
from datetime import datetime

# Ensure we're in the right directory
os.chdir(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, '.')


def run_pipeline(hours: int = 24, use_ai: bool = True, dry_run: bool = False, save_snapshot: bool = False):
    """Run the complete monitoring pipeline"""
    from agents.interaction_monitor import analyze_interactions, generate_report as monitor_report
    from agents.issue_validator import validate_issues, generate_report as validator_report, analyze_patterns
    from agents.resolution_tracker import calculate_health_metrics, save_health_snapshot, get_open_issues, detect_regressions

    print("=" * 70)
    print("  REMYNDRS MONITORING PIPELINE")
    print(f"  Started: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}")
    print("=" * 70)
    print()

    validator_results = None

    # ========================================
    # AGENT 1: Interaction Monitor
    # ========================================
    print("â”Œ" + "â”€" * 68 + "â”")
    print("â”‚ AGENT 1: Interaction Monitor" + " " * 38 + "â”‚")
    print("â””" + "â”€" * 68 + "â”˜")
    print(f"  Analyzing last {hours} hours of interactions...")
    print()

    monitor_results = analyze_interactions(hours=hours, dry_run=dry_run)

    print(f"  âœ“ Logs analyzed: {monitor_results['logs_analyzed']}")
    print(f"  âœ“ Issues detected: {len(monitor_results['issues_found'])}")

    if monitor_results.get('summary'):
        print("\n  Issues by type:")
        for issue_type, count in sorted(monitor_results['summary'].items(), key=lambda x: -x[1]):
            severity_icon = {
                'delivery_failure': 'ðŸš¨',
                'error_response': 'âŒ',
                'failed_action': 'âš ï¸',
                'timezone_issue': 'ðŸŒ',
                'user_confusion': 'â“',
                'parsing_failure': 'ðŸ”',
                'confidence_rejection': 'ðŸŽ¯',
                'repeated_attempts': 'ðŸ”„',
            }.get(issue_type, 'â€¢')
            print(f"    {severity_icon} {issue_type}: {count}")

    print()

    # ========================================
    # AGENT 2: Issue Validator
    # ========================================
    print("â”Œ" + "â”€" * 68 + "â”")
    print("â”‚ AGENT 2: Issue Validator" + " " * 42 + "â”‚")
    print("â””" + "â”€" * 68 + "â”˜")

    pending_count = len(monitor_results['issues_found'])
    if pending_count == 0:
        print("  No new issues to validate.")
        print()
    else:
        print(f"  Validating {pending_count} issues (AI: {use_ai})...")
        print()

        validator_results = validate_issues(
            limit=100,
            use_ai=use_ai,
            dry_run=dry_run
        )

        print(f"  âœ“ Issues processed: {validator_results['issues_processed']}")
        print(f"  âœ“ Real issues: {len(validator_results['validated'])}")
        print(f"  âœ“ False positives: {len(validator_results['false_positives'])}")

        if validator_results['issues_processed'] > 0:
            fp_rate = len(validator_results['false_positives']) / validator_results['issues_processed'] * 100
            print(f"  âœ“ Detection accuracy: {100 - fp_rate:.1f}%")

        if validator_results.get('patterns_found'):
            print("\n  Patterns identified:")
            for pattern, count in validator_results['patterns_found'].items():
                print(f"    â€¢ {pattern}: {count} issues")

        if validator_results.get('severity_adjustments'):
            print(f"\n  Severity adjustments: {len(validator_results['severity_adjustments'])}")

    print()

    # ========================================
    # AGENT 3: Resolution Tracker
    # ========================================
    print("â”Œ" + "â”€" * 68 + "â”")
    print("â”‚ AGENT 3: Resolution Tracker" + " " * 39 + "â”‚")
    print("â””" + "â”€" * 68 + "â”˜")

    # Calculate health metrics
    health = calculate_health_metrics(days=7)

    status_icons = {
        'excellent': 'ðŸŸ¢',
        'good': 'ðŸŸ¢',
        'fair': 'ðŸŸ¡',
        'poor': 'ðŸŸ ',
        'critical': 'ðŸ”´'
    }
    icon = status_icons.get(health['health_status'], 'âšª')

    print(f"\n  {icon} HEALTH SCORE: {health['health_score']:.0f}/100 ({health['health_status'].upper()})")
    print()
    print(f"  âœ“ Total interactions (7d): {health['total_interactions']:,}")
    print(f"  âœ“ Issue rate: {health['issue_rate']}%")
    print(f"  âœ“ Resolution rate: {health['resolution_rate']}%")
    print(f"  âœ“ Open issues: {health['open_issues']}")

    # Check for regressions
    if not dry_run:
        regressions = detect_regressions()
        if regressions:
            print(f"\n  âš ï¸  REGRESSIONS DETECTED: {len(regressions)}")
            for r in regressions[:3]:
                print(f"    â€¢ {r['pattern_name']}: {r['new_issues_since']} new issues since fix")

    # Save snapshot if requested
    if save_snapshot and not dry_run:
        save_health_snapshot(health)
        print(f"\n  âœ“ Daily health snapshot saved")

    print()

    # ========================================
    # SUMMARY
    # ========================================
    print("â”Œ" + "â”€" * 68 + "â”")
    print("â”‚ PIPELINE SUMMARY" + " " * 50 + "â”‚")
    print("â””" + "â”€" * 68 + "â”˜")

    # Get pattern analysis
    patterns = analyze_patterns()

    print(f"\n  Total issues in system:")
    if patterns.get('type_distribution'):
        for td in patterns['type_distribution'][:5]:
            bar_len = min(td['total'], 20)
            bar = "â–ˆ" * bar_len
            print(f"    {td['type']:22} {bar:20} {td['total']:3} ({td['accuracy']}% real)")

    if patterns.get('top_affected_users'):
        print(f"\n  Users needing attention:")
        for u in patterns['top_affected_users'][:3]:
            print(f"    {u['phone']}: {u['count']} issues")

    # Show open issues needing resolution
    open_issues = get_open_issues(limit=5)
    if open_issues:
        print(f"\n  ðŸ“‹ Open issues needing resolution:")
        for issue in open_issues:
            sev_icon = {'critical': 'ðŸ”´', 'high': 'ðŸŸ ', 'medium': 'ðŸŸ¡', 'low': 'ðŸŸ¢'}.get(issue['severity'], 'âšª')
            print(f"    {sev_icon} #{issue['id']} [{issue['severity']:8}] {issue['issue_type']}")

    if patterns.get('patterns') and any(p['count'] >= 3 for p in patterns['patterns']):
        print(f"\n  ðŸŽ¯ Action items (patterns with 3+ issues):")
        for p in patterns['patterns']:
            if p['count'] >= 3:
                print(f"    â€¢ {p['name']}: {p['count']} issues")
                if p.get('description'):
                    print(f"      â””â”€ {p['description']}")

    print()
    print("=" * 70)
    print(f"  Pipeline completed: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}")
    if dry_run:
        print("  (DRY RUN - no changes saved)")
    print("=" * 70)

    return {
        'monitor': monitor_results,
        'validator': validator_results,
        'health': health,
        'patterns': patterns
    }


def main():
    parser = argparse.ArgumentParser(
        description='Run the complete monitoring pipeline (Agent 1 + Agent 2 + Agent 3)'
    )
    parser.add_argument(
        '--hours', type=int, default=24,
        help='Hours of history to analyze (default: 24)'
    )
    parser.add_argument(
        '--no-ai', action='store_true',
        help='Disable AI validation in Agent 2'
    )
    parser.add_argument(
        '--report', action='store_true',
        help='Dry run - analyze only, no database writes'
    )
    parser.add_argument(
        '--snapshot', action='store_true',
        help='Save daily health snapshot (for scheduled runs)'
    )

    args = parser.parse_args()

    run_pipeline(
        hours=args.hours,
        use_ai=not args.no_ai,
        dry_run=args.report,
        save_snapshot=args.snapshot
    )


if __name__ == '__main__':
    main()
